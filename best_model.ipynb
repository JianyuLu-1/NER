{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "best model",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5dYiotYhpr1",
        "outputId": "a27cd87c-d3ad-4b8b-a868-1c182d6c9f6c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMBwkY6Khqrq"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/train.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/val.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/test_without_labels.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCRvRvUwhrvd"
      },
      "source": [
        "# get labels\n",
        "train_label_raw = list(train_df.labels)\n",
        "val_label_raw = list(val_df.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyiFXW_NhtP1"
      },
      "source": [
        "train_labels = []\n",
        "for label in train_label_raw:\n",
        "    train_labels.append(label.split(\" \"))\n",
        "\n",
        "val_labels = []\n",
        "for label in val_label_raw:\n",
        "    val_labels.append(label.split(\" \"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZwri0EMhuin",
        "outputId": "659c51b8-caba-42e8-f04a-75a3fbc63f90"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "def get_lemmatized_tokens(dataframe):\n",
        "  \"\"\"\n",
        "  Extract sentences from dataframe and output stemmed tokens and related NER\n",
        "  Extract labels from dataframe and tokenize it\n",
        "  \"\"\"\n",
        "  sentences = list(dataframe.sents)\n",
        "\n",
        "  tokenized_sentences = []\n",
        "  for sentence in sentences:\n",
        "    tokens = sentence.split(\" \")\n",
        "    tokenized_sentences.append(tokens)\n",
        "\n",
        "  lemmatized_sentences = []\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "  for sentence in tokenized_sentences:\n",
        "    lemmatized = [lemmatizer.lemmatize(word, pos='v').lower() for word in sentence]\n",
        "    lemmatized_sentences.append(lemmatized)\n",
        "\n",
        "  return lemmatized_sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLL9S7vKhxoz"
      },
      "source": [
        "train_tokens = get_lemmatized_tokens(train_df)\n",
        "val_tokens = get_lemmatized_tokens(val_df)\n",
        "test_tokens = get_lemmatized_tokens(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk8V-Qtohx-K"
      },
      "source": [
        "all_tokens = train_tokens + val_tokens + test_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN5WBzhWhzQt"
      },
      "source": [
        "word_to_ix = {}\n",
        "for sentence in all_tokens:\n",
        "    for word in sentence:\n",
        "        word = word.lower()\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "\n",
        "for tags in train_labels:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwtaBMGyh1rn",
        "outputId": "4718f9aa-bb7e-432a-edb2-4df36992594e"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "def generate_pos_tag(doc):\n",
        "  \"\"\"\n",
        "  :param doc_words: words in doc\n",
        "  :return: pos tags\n",
        "  \"\"\"\n",
        "  pos_tags = []\n",
        "  for sentence in doc:\n",
        "    tags = []\n",
        "    for word, tag in nltk.pos_tag(sentence):\n",
        "      tags.append(tag)\n",
        "    pos_tags.append(tags)\n",
        " \n",
        "  return pos_tags\n",
        "\n",
        "pos_tags = generate_pos_tag(all_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMJ79QsPh4Sc"
      },
      "source": [
        "# use word2vec to train the embeddings for pos\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v_pos = Word2Vec(sentences=pos_tags, \n",
        "                   size=20, \n",
        "                   window=3,\n",
        "                   min_count=1,\n",
        "                   workers=4,\n",
        "                   sg=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiYb2mWbh5od"
      },
      "source": [
        "#Lab 7 \n",
        "import spacy\n",
        "\n",
        "#load the spacy api with the pre-trained statistical models for English. English multi-task CNN trained on OntoNotes\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(data):\n",
        "    parse_sentences_temp=[]\n",
        "    for sentence in data:\n",
        "        parse = nlp(' '.join(sentence))\n",
        "        deps = []\n",
        "        for x in parse:\n",
        "          deps.append(x.dep_)\n",
        "\n",
        "        parse_sentences_temp.append(deps[:len(sentence)])\n",
        "    return parse_sentences_temp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQZoTtf4h7-0"
      },
      "source": [
        "parse_sentences = parse_sentence(all_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEKq2G72SU9c",
        "outputId": "c2378c09-736e-4794-c3ef-18dba8e2327a"
      },
      "source": [
        "parse_sentences[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['compound',\n",
              " 'compound',\n",
              " 'nsubj',\n",
              " 'punct',\n",
              " 'parataxis',\n",
              " 'punct',\n",
              " 'punct',\n",
              " 'nmod',\n",
              " 'intj',\n",
              " 'intj',\n",
              " 'punct',\n",
              " 'nmod',\n",
              " 'intj',\n",
              " 'compound',\n",
              " 'compound',\n",
              " 'compound',\n",
              " 'nmod',\n",
              " 'intj',\n",
              " 'compound',\n",
              " 'compound',\n",
              " 'compound',\n",
              " 'compound',\n",
              " 'appos',\n",
              " 'punct',\n",
              " 'ROOT',\n",
              " 'det',\n",
              " 'amod',\n",
              " 'attr',\n",
              " 'attr',\n",
              " 'agent',\n",
              " 'compound',\n",
              " 'pobj',\n",
              " 'prep',\n",
              " 'amod',\n",
              " 'pobj',\n",
              " 'nummod',\n",
              " 'aux',\n",
              " 'advcl',\n",
              " 'det',\n",
              " 'dobj',\n",
              " 'prep',\n",
              " 'amod',\n",
              " 'pobj',\n",
              " 'advcl',\n",
              " 'det',\n",
              " 'dobj',\n",
              " 'cc',\n",
              " 'conj',\n",
              " 'det',\n",
              " 'amod',\n",
              " 'dobj',\n",
              " 'punct']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxu3k4aOjmFV"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "w2v_parse_tree = Word2Vec(sentences=parse_sentences, \n",
        "                   size=20, \n",
        "                   window=3,\n",
        "                   min_count=1,\n",
        "                   workers=4,\n",
        "                   sg=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_btv7RHh9Qb",
        "outputId": "5158a2af-f753-495e-fce7-12745104a7af"
      },
      "source": [
        "word_2_pos={}\n",
        "for i in range(0,len(all_tokens)):\n",
        "    for x in range(0,len(all_tokens[i])):\n",
        "        word_2_pos[all_tokens[i][x]] = w2v_pos[pos_tags[i][x]]\n",
        "\n",
        "word_2_pt={}\n",
        "for i in range(0,len(all_tokens)):\n",
        "    for x in range(0,len(all_tokens[i])):\n",
        "        word_2_pt[all_tokens[i][x]] = w2v_parse_tree[parse_sentences[i][x]]  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73p_Ug3qh-f9",
        "outputId": "265b12b5-3873-4f50-b7bd-a12ce1906f98"
      },
      "source": [
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "word_emb_model = api.load(\"glove-twitter-100\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O4Kt4jhh_yZ",
        "outputId": "1af4ece3-e865-48b3-b4bf-476c08e65c20"
      },
      "source": [
        "# 100 w2v + 20 pos + 20 tree\n",
        "EMBEDDING_DIM = 140\n",
        "embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        a = word_emb_model.wv[word]\n",
        "        b = np.append(a, word_2_pos[word])\n",
        "        c = np.append(b, word_2_pt[word])\n",
        "        \n",
        "        # 加到这里 - 向量化\n",
        "        # word_embedding_temp.extend(len(word))\n",
        "        embedding_matrix.append(c)\n",
        "    except:\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
        "\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3408, 140)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DKEoM2DiBos"
      },
      "source": [
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "train_input_index =  to_index(train_tokens,word_to_ix)\n",
        "train_output_index = to_index(train_labels,tag_to_ix)\n",
        "val_input_index = to_index(val_tokens,word_to_ix)\n",
        "val_output_index = to_index(val_labels,tag_to_ix)\n",
        "test_input_index = to_index(test_tokens,word_to_ix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eaUc3JxNeJ9"
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "\n",
        "\n",
        "## stacked bi-lstm layer >= 1\n",
        "## attention - 至少三种 attention\n",
        "## CRF layer, 有或者，没有\n",
        "\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, layers):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        \n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "      \n",
        "\n",
        "        self.layers = layers\n",
        "        \n",
        "                                                                          ## batch_size * dim1 * dim2\n",
        "        self.general_attention_weight = nn.parameter.Parameter(torch.Tensor(1, self.hidden_dim, self.hidden_dim), requires_grad = True)\n",
        "        \n",
        "       \n",
        "\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim * 2, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "        self.attn = torch.nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2*self.layers, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2*self.layers, 1, self.hidden_dim // 2).to(device))\n",
        "      \n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        \n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        ## attention part    \n",
        "    \n",
        "        query = lstm_out.view(lstm_out.size(1), lstm_out.size(0), lstm_out.size(2))\n",
        "        \n",
        "        key = lstm_out.view(lstm_out.size(1), lstm_out.size(2), lstm_out.size(0))\n",
        "        \n",
        "        value = lstm_out.view(lstm_out.size(1), lstm_out.size(0), lstm_out.size(2))\n",
        "        \n",
        "        weight_att = nn.functional.softmax(torch.bmm(query, key),dim=-1)\n",
        "        \n",
        "      \n",
        "\n",
        "        output = torch.bmm(weight_att, value)\n",
        "        concat_output = torch.cat((output, value), dim = -1)\n",
        "        lstm_out = concat_output.view(len(sentence), self.hidden_dim * 2)\n",
        "        \n",
        "\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "      \n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        \n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        \n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        \n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        \n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        \n",
        "        # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "          \n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        \n",
        "        return score, tag_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNZdDfzEiWIq"
      },
      "source": [
        "import numpy as np\n",
        "def cal_acc(model, input_index, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        ground_truth += output_index[i]\n",
        "        score, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred\n",
        "    accuracy = sum(np.array(ground_truth) == np.array(predicted))/len(ground_truth)\n",
        "    return predicted, ground_truth, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBHj_YkPiYsX"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "HIDDEN_DIM = 50\n",
        "\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers = 1).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.005, weight_decay=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE5eMOd6idQA"
      },
      "source": [
        "train_data=train_input_index+val_input_index\n",
        "train_label=train_output_index+val_output_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHfti7MTifaM",
        "outputId": "e308564a-c910-4fb2-baec-a3b92765fe5a"
      },
      "source": [
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "import datetime\n",
        "attention_train_loss = []\n",
        "attention_val_loss = []\n",
        "for epoch in range(20):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    \n",
        "    for i, idxs in enumerate(train_data):\n",
        "\n",
        "        tags_index = train_label[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        \n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        \n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        \n",
        "        \n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "    attention_train_loss.append(train_loss)\n",
        "    max_val_acc=0\n",
        "    model.eval()\n",
        "    _, _, train_acc = cal_acc(model, train_input_index, train_output_index)\n",
        "    _, _, val_acc = cal_acc(model, val_input_index, val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    attention_val_loss.append(val_loss)\n",
        "    time2 = datetime.datetime.now()\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train_acc: %.4f, val loss: %.2f, val_acc: %.4f, time: %.2fs\" %(epoch+1, train_loss, train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 22154.86, train_acc: 0.7398, val loss: 4573.85, val_acc: 0.6942, time: 120.94s\n",
            "Epoch:2, Training loss: 13507.29, train_acc: 0.7841, val loss: 3228.08, val_acc: 0.7429, time: 122.17s\n",
            "Epoch:3, Training loss: 10464.66, train_acc: 0.8229, val loss: 2540.91, val_acc: 0.7975, time: 121.81s\n",
            "Epoch:4, Training loss: 8771.06, train_acc: 0.8329, val loss: 2150.33, val_acc: 0.8072, time: 121.87s\n",
            "Epoch:5, Training loss: 7625.51, train_acc: 0.8405, val loss: 1881.04, val_acc: 0.8140, time: 122.26s\n",
            "Epoch:6, Training loss: 6808.34, train_acc: 0.8510, val loss: 1637.95, val_acc: 0.8385, time: 122.60s\n",
            "Epoch:7, Training loss: 6089.71, train_acc: 0.8646, val loss: 1490.22, val_acc: 0.8489, time: 122.62s\n",
            "Epoch:8, Training loss: 5667.21, train_acc: 0.8699, val loss: 1331.14, val_acc: 0.8667, time: 122.63s\n",
            "Epoch:9, Training loss: 5268.89, train_acc: 0.8745, val loss: 1228.78, val_acc: 0.8739, time: 123.29s\n",
            "Epoch:10, Training loss: 4874.40, train_acc: 0.8918, val loss: 1124.07, val_acc: 0.8876, time: 122.96s\n",
            "Epoch:11, Training loss: 4560.89, train_acc: 0.8933, val loss: 1055.12, val_acc: 0.8823, time: 121.87s\n",
            "Epoch:12, Training loss: 4266.19, train_acc: 0.8984, val loss: 997.18, val_acc: 0.8879, time: 121.93s\n",
            "Epoch:13, Training loss: 3980.89, train_acc: 0.9087, val loss: 921.01, val_acc: 0.9003, time: 122.64s\n",
            "Epoch:14, Training loss: 3755.14, train_acc: 0.9212, val loss: 837.64, val_acc: 0.9151, time: 123.56s\n",
            "Epoch:15, Training loss: 3582.37, train_acc: 0.9142, val loss: 792.00, val_acc: 0.9139, time: 123.01s\n",
            "Epoch:16, Training loss: 3370.04, train_acc: 0.9289, val loss: 738.77, val_acc: 0.9207, time: 122.99s\n",
            "Epoch:17, Training loss: 3115.31, train_acc: 0.9274, val loss: 682.66, val_acc: 0.9247, time: 123.47s\n",
            "Epoch:18, Training loss: 2996.29, train_acc: 0.9264, val loss: 624.15, val_acc: 0.9297, time: 122.04s\n",
            "Epoch:19, Training loss: 2881.81, train_acc: 0.9307, val loss: 621.66, val_acc: 0.9350, time: 121.78s\n",
            "Epoch:20, Training loss: 2740.18, train_acc: 0.9311, val loss: 623.49, val_acc: 0.9268, time: 121.63s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez9TuPnxwamY"
      },
      "source": [
        "torch.save(model, \"best_model.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbTVSnf9AHDO"
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "model_best = torch.load('97% model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl_VL9AlweJI"
      },
      "source": [
        "ix_2_tag = {idx : tag for tag, idx in tag_to_ix.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4pdzkozxEi3"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "res = []\n",
        "for x in test_input_index:\n",
        "  input_tensor = torch.tensor(x).to(device)\n",
        "  _, output = model_best(input_tensor)\n",
        "\n",
        "  for i in output:\n",
        "    res.append(ix_2_tag[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4lmX4sPztiw"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data_re=pd.core.frame.DataFrame({'Id':range(len(res)) ,'Predicted':res })\n",
        "data_re.to_csv('result.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8HjVNIIIykX"
      },
      "source": [
        "reference ：\n",
        "1. Vaswani, A., Shazeer, N.M., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., & Polosukhin, I.. Attention is All you Need. ArXiv, abs/1706.03762. (2017).\n",
        "2. Zhou, P., Shi, W., Tian, J., Qi, Z., Li, B., Hao, H., & Xu, B.. Attention-based bidirectional long short-term memory networks for relation classification.  in Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) pp. 207–212.  (2016).\n",
        "3. lab 7, lab 9, lab 10\n",
        "4. SSBakhSSBakh                    1, et al. “How to Use pos_tag in NLTK?” Stack Overflow, https://stackoverflow.com/questions/47519987/how-to-use-pos-tag-in-nltk. (n.d.)\n",
        "\n",
        "\n",
        "5. Gensim: topic modelling for humans. models.word2vec – Word2vec embeddings - gensim. https://radimrehurek.com/gensim/models/word2vec.html.  (2021, April 29)\n"
      ]
    }
  ]
}